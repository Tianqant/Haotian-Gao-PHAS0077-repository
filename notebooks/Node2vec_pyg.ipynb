{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucGmFZb5vN7z","executionInfo":{"status":"ok","timestamp":1658762329128,"user_tz":-60,"elapsed":16813,"user":{"displayName":"Group Three","userId":"07771823321101088643"}},"outputId":"57da1700-532c-405f-caac-c6b1ded2e42f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["# Install project requirements to Colab runtime\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","! pip3 install -r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lsF2VTv3vNyq","outputId":"655eb737-576e-4b19-aef1-003f31f16236","executionInfo":{"status":"ok","timestamp":1658762490715,"user_tz":-60,"elapsed":152308,"user":{"displayName":"Group Three","userId":"07771823321101088643"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch@ https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp37-cp37m-linux_x86_64.whl\n","  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (1637.0 MB)\n","\u001b[K     |████████████████▎               | 834.1 MB 1.2 MB/s eta 0:11:08tcmalloc: large alloc 1147494400 bytes == 0x2fda000 @  0x7f3e4b292615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████▋           | 1055.7 MB 1.1 MB/s eta 0:08:31tcmalloc: large alloc 1434370048 bytes == 0x47630000 @  0x7f3e4b292615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |██████████████████████████▏     | 1336.2 MB 82.9 MB/s eta 0:00:04tcmalloc: large alloc 1792966656 bytes == 0x9ce1c000 @  0x7f3e4b292615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 1636.9 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 1636958208 bytes == 0x2fda000 @  0x7f3e4b2911e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n","tcmalloc: large alloc 2046197760 bytes == 0x107c04000 @  0x7f3e4b292615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n","\u001b[K     |████████████████████████████████| 1637.0 MB 6.5 kB/s \n","\u001b[?25hCollecting torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e\n","  Cloning https://github.com/pyg-team/pytorch_geometric.git (to revision 6c6e2cc1c350d97eeeab20f698fb1c506aed441e) to /tmp/pip-install-tcn_n96j/torch-geometric_f58150e85746436daacce63bc72460cb\n","  Running command git clone -q https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-install-tcn_n96j/torch-geometric_f58150e85746436daacce63bc72460cb\n","  Running command git rev-parse -q --verify 'sha^6c6e2cc1c350d97eeeab20f698fb1c506aed441e'\n","  Running command git fetch -q https://github.com/pyg-team/pytorch_geometric.git 6c6e2cc1c350d97eeeab20f698fb1c506aed441e\n","  Running command git checkout -q 6c6e2cc1c350d97eeeab20f698fb1c506aed441e\n","Collecting torch-scatter@ https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl\n","  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n","\u001b[K     |████████████████████████████████| 7.9 MB 2.7 MB/s \n","\u001b[?25hCollecting torch-sparse@ https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl\n","  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 45.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch@ https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp37-cp37m-linux_x86_64.whl->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 1)) (4.1.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 2)) (4.64.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 2)) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 2)) (1.7.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 2)) (2.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 2)) (2.23.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 2)) (3.0.9)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 2)) (1.0.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 2)) (2.0.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 2)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 2)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 2)) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 2)) (1.24.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 2)) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric@ git+https://github.com/pyg-team/pytorch_geometric.git@6c6e2cc1c350d97eeeab20f698fb1c506aed441e->-r /content/gdrive/MyDrive/cdt-gnn-returns/asos-gnn-returns-requirements-colab.txt (line 2)) (1.1.0)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.0.5-py3-none-any.whl size=661215 sha256=32d620feaf6cecc1286e257735ef80814d03f93e06fed01dedac26cb459e7ab4\n","  Stored in directory: /root/.cache/pip/wheels/ad/63/f0/00678e33a9f7cd92997b061e274920e2d071766132e0cd9bc5\n","Successfully built torch-geometric\n","Installing collected packages: torch-sparse, torch-scatter, torch-geometric, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.0+cu113\n","    Uninstalling torch-1.12.0+cu113:\n","      Successfully uninstalled torch-1.12.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.0+cu113 requires torch==1.12.0, but you have torch 1.11.0+cu113 which is incompatible.\n","torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.11.0+cu113 which is incompatible.\n","torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.11.0+cu113 which is incompatible.\u001b[0m\n","Successfully installed torch-1.11.0+cu113 torch-geometric-2.0.5 torch-scatter-2.0.9 torch-sparse-0.6.13\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"Q7fzaahxvNnS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x_yTedWTumni"},"outputs":[],"source":["from typing import Callable, List, Optional\n","import os.path as osp\n","import torch\n","from torch_geometric.data import (HeteroData, InMemoryDataset, download_url,\n","                                  extract_zip)\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","# device = \"cpu\"\n","\n","class ASOSGnnDataNode2Vec(InMemoryDataset):\n","    r\"\"\"A heterogeneous rating dataset, assembled by GroupLens Research from\n","    the `MovieLens web site <https://movielens.org>`_, consisting of nodes of\n","    type :obj:`\"movie\"` and :obj:`\"user\"`.\n","    User ratings for movies are available as ground truth labels for the edges\n","    between the users and the movies :obj:`(\"user\", \"rates\", \"movie\")`.\n","\n","    Args:\n","        root (string): Root directory where the dataset should be saved.\n","        transform (callable, optional): A function/transform that takes in an\n","            :obj:`torch_geometric.data.HeteroData` object and returns a\n","            transformed version. The data object will be transformed before\n","            every access. (default: :obj:`None`)\n","        pre_transform (callable, optional): A function/transform that takes in\n","            an :obj:`torch_geometric.data.HeteroData` object and returns a\n","            transformed version. The data object will be transformed before\n","            being saved to disk. (default: :obj:`None`)\n","        model_name (str): Name of model used to transform movie titles to node\n","            features. The model comes from the`Huggingface SentenceTransformer\n","            <https://huggingface.co/sentence-transformers>`_.\n","    \"\"\"\n","\n","    def __init__(self, root, transform: Optional[Callable] = None,\n","                 pre_transform: Optional[Callable] = None,\n","                 model_name: Optional[str] = \"asos-gnn-model\"):\n","        self.model_name = model_name\n","        super().__init__(root, transform, pre_transform)\n","        self.data, self.slices = torch.load(self.processed_paths[0])\n","\n","    reduced = 0\n","    \n","    if reduced ==1:\n","        # reduced data\n","        @property\n","        def raw_file_names(self) -> List[str]:\n","            return #[\n","                #osp.join('gnn_reduced_data', 'filterd_customer_nodes_training.csv'),\n","                #osp.join('gnn_reduced_data', 'filterd_product_nodes_training.csv'),\n","                #osp.join('gnn_reduced_data', 'filterd_event_table_training.csv'),\n","                #osp.join('gnn_reduced_data', 'filterd_esvent_table_testing.csv'),\n","            #] \n","            [\n","                osp.join('gnn_reduced_data', 'filterd_customer_nodes_training.csv'),\n","                osp.join('gnn_reduced_data', 'filterd_product_nodes_training.csv'),\n","                osp.join('gnn_reduced_data', 'filterd_event_table_training.csv'),\n","                osp.join('gnn_reduced_data', 'filterd_event_table_testing.csv'),\n","            ] \n","        @property\n","        def processed_file_names(self) -> str:\n","            return f'data_node2vec_reduced_{self.model_name}.pt'\n","        \n","    else:\n","        # full data    \n","        @property\n","        def raw_file_names(self) -> List[str]:\n","            return [\n","                osp.join('gnn_data', 'customer_nodes_training.csv'),\n","                osp.join('gnn_data', 'product_nodes_training.csv'),\n","                osp.join('gnn_data', 'event_table_training.csv'),\n","                osp.join('gnn_data', 'event_table_testing.csv'),\n","            ]\n","        @property\n","        def processed_file_names(self) -> str:\n","            return f'data_node2vec_{self.model_name}.pt'\n","\n","    def download(self):\n","        pass\n","\n","    def process(self):\n","        import pandas as pd\n","        # from sentence_transformers import SentenceTransformer\n","\n","        data = HeteroData()\n","\n","        df_customers = pd.read_csv(self.raw_paths[0]).drop([\"shippingCountry\"],\n","                                                               axis=1).dropna()\n","        \n","        df_customers.insert(0, \"customer_id\", range(0, len(df_customers)))\n","        \n","        df_products = pd.read_csv(self.raw_paths[1]).drop([\"brandDesc\"],\n","                                                              axis=1).dropna()\n","        \n","        df_products.insert(0, \"product_id\", \n","                           range(0, len(df_products)))\n","#                            range(len(df_customers) + 1, len(df_customers) + 1 + len(df_products)))\n","        \n","        df_events = pd.read_csv(self.raw_paths[2]).dropna()\n","        \n","        df_events = df_events.merge(df_customers[[\"hash(customerId)\", \"customer_id\"]], \n","                                    on=\"hash(customerId)\", how=\"inner\")\n","        df_valid_events = df_events.merge(df_products[[\"variantID\", \"product_id\"]], \n","                                          on=\"variantID\", how=\"inner\")\n","        \n","                \n","        customer_src = torch.tensor(df_valid_events[\"customer_id\"])\n","        product_dst = torch.tensor(df_valid_events[\"product_id\"])\n","\n","        edge_index = torch.stack([customer_src, product_dst])\n","\n","        returned = torch.from_numpy(df_valid_events['isReturned'].values).to(torch.bool)\n","        \n","        return_edge_index = edge_index[:,returned]\n","#         kept_edge_index = edge_index[:,!returned]\n","\n","\n","        # include event from test set\n","        df_events_test = pd.read_csv(self.raw_paths[3]).dropna()\n","        \n","        df_events_test = df_events_test.merge(df_customers[[\"hash(customerId)\", \"customer_id\"]], \n","                                    on=\"hash(customerId)\", how=\"inner\")\n","        df_valid_events_test = df_events_test.merge(df_products[[\"variantID\", \"product_id\"]], \n","                                          on=\"variantID\", how=\"inner\")\n","        \n","        customer_src_test = torch.tensor(df_valid_events_test[\"customer_id\"])\n","        product_dst_test = torch.tensor(df_valid_events_test[\"product_id\"])\n","\n","        edge_index_test = torch.stack([customer_src_test, product_dst_test])\n","\n","        returned_test = torch.from_numpy(df_valid_events_test['isReturned'].values).to(torch.bool)\n","        \n","        return_edge_index_test = edge_index_test[:,returned_test]\n","#         kept_edge_index_test = edge_index_test[:,!returned_test]\n","        \n","        \n","        \n","        \n","        df_customers = df_customers.set_index(\"customer_id\")\n","        df_products = df_products.set_index(\"product_id\")\n","\n","        df_products = df_products.drop('productType', axis=1)\n","\n","        # modified here\n","        df_products = df_products.astype(float)\n","        \n","        data['customer'].x = torch.from_numpy(df_customers.to_numpy()).to(torch.float)        \n","        data['product'].x = torch.from_numpy(df_products.to_numpy()).to(torch.float)\n","        \n","        data['customer', 'purchases', 'product'].edge_index = edge_index.to(torch.long)\n","        data['customer', 'purchases', 'product'].edge_label = returned.to(torch.long)\n","        data['product', 'purchased_by', 'customer'].edge_index = torch.flip(edge_index.to(torch.long), [0])\n","        \n","        # create purchase edges for test events\n","        data['customer', 'purchases_test', 'product'].edge_index = edge_index_test.to(torch.long)\n","        data['customer', 'purchases_test', 'product'].edge_label = returned_test.to(torch.long)\n","        data['product', 'purchased_by_test', 'customer'].edge_index = torch.flip(edge_index_test.to(torch.long), [0])\n","        \n","#         data['customer', 'keeps', 'product'].edge_index = kept_edge_index.to(torch.long)\n","#         data['product', 'kept_by', 'customer'].edge_index = torch.flip(kept_edge_index.to(torch.long), [0])\n","\n","        data['customer', 'returns', 'product'].edge_index = return_edge_index.to(torch.long)\n","        data['product', 'returned_by', 'customer'].edge_index = torch.flip(return_edge_index.to(torch.long), [0])\n","        \n","        \n","        # create return edges for test events\n","        data['customer', 'returns_test', 'product'].edge_index = return_edge_index_test.to(torch.long)\n","        data['product', 'returned_by_test', 'customer'].edge_index = torch.flip(return_edge_index_test.to(torch.long), [0])\n","        \n","        \n","        customer_nodes = int(edge_index[0].max() + 1)\n","        product_nodes = int(edge_index[1].max() + 1)\n","        data['customer'].num_nodes = customer_nodes\n","        data['product'].num_nodes = product_nodes\n","        \n","        data['customer'].node_index = torch.arange(0, customer_nodes)\n","        data['product'].node_index = torch.arange(0, product_nodes)\n","        \n","        if self.pre_transform is not None:\n","            data = self.pre_transform(data)\n","\n","        torch.save(self.collate([data]), self.processed_paths[0])"]},{"cell_type":"code","source":["import os\n","path = '/content/gdrive/MyDrive/cdt-gnn-returns/src'\n","os.chdir(path)\n","print(os.getcwd())"],"metadata":{"id":"xjAjUUGrvLod","executionInfo":{"status":"ok","timestamp":1658762523068,"user_tz":-60,"elapsed":194,"user":{"displayName":"Group Three","userId":"07771823321101088643"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c6ecc321-5176-4e0a-bace-245789611552"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/cdt-gnn-returns/src\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"cei9D793vLyP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OrYcq_x-umnm","executionInfo":{"status":"ok","timestamp":1658762855088,"user_tz":-60,"elapsed":24068,"user":{"displayName":"Group Three","userId":"07771823321101088643"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b1e9a7e4-0841-4960-e63c-2438c512a5f6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["HeteroData(\n","  \u001b[1mcustomer\u001b[0m={\n","    x=[652518, 30],\n","    num_nodes=652518,\n","    node_index=[652518]\n","  },\n","  \u001b[1mproduct\u001b[0m={\n","    x=[431696, 41],\n","    num_nodes=431695,\n","    node_index=[431695]\n","  },\n","  \u001b[1m(customer, purchases, product)\u001b[0m={\n","    edge_index=[2, 1000000],\n","    edge_label=[1000000]\n","  },\n","  \u001b[1m(product, purchased_by, customer)\u001b[0m={ edge_index=[2, 1000000] },\n","  \u001b[1m(customer, purchases_test, product)\u001b[0m={\n","    edge_index=[2, 174865],\n","    edge_label=[174865]\n","  },\n","  \u001b[1m(product, purchased_by_test, customer)\u001b[0m={ edge_index=[2, 174865] },\n","  \u001b[1m(customer, returns, product)\u001b[0m={ edge_index=[2, 560813] },\n","  \u001b[1m(product, returned_by, customer)\u001b[0m={ edge_index=[2, 560813] },\n","  \u001b[1m(customer, returns_test, product)\u001b[0m={ edge_index=[2, 100195] },\n","  \u001b[1m(product, returned_by_test, customer)\u001b[0m={ edge_index=[2, 100195] }\n",")"]},"metadata":{},"execution_count":6}],"source":["gnnData = ASOSGnnDataNode2Vec(root=\"../\")\n","gnnData.process()\n","dataset = gnnData.data\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V61vIk0Aumnn"},"outputs":[],"source":["from torch_geometric.nn import MetaPath2Vec\n","\n","metapath = [\n","     (\"customer\", \"purchases\", \"product\"),\n","     (\"product\", \"purchased_by\", \"customer\"),\n","    (\"customer\", \"returns\", \"product\"),\n","    (\"product\", \"returned_by\", \"customer\")\n","]\n","\n","model = MetaPath2Vec(dataset.edge_index_dict,\n","                     embedding_dim=128,\n","                     metapath=metapath,\n","                     walk_length=5,\n","                     context_size=3,\n","                     walks_per_node=10,\n","                     num_negative_samples=1,\n","                     sparse=True).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"deCwnesAumno"},"outputs":[],"source":["# use the loader to build a loader\n","loader = model.loader(batch_size=128, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"dTGQuBogumno","outputId":"d5690a01-cb9d-49cd-f80c-e1eb3a04f793","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658324081550,"user_tz":-60,"elapsed":209,"user":{"displayName":"Group Three","userId":"07771823321101088643"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 238161,  891341,  426765],\n","         [ 117735,  834539,  542066],\n","         [ 326635,  965400,   82611],\n","         ...,\n","         [1008420,  624781, 1008420],\n","         [1084213, 1084213, 1084213],\n","         [1084213, 1084213, 1084213]]), tensor([[ 238161, 1057643,  206586],\n","         [ 117735, 1060734,  333777],\n","         [ 326635,  959335,  542282],\n","         ...,\n","         [ 820336,  390538, 1039993],\n","         [ 934015,  455735, 1002350],\n","         [ 877296,  628058,  862318]]))"]},"metadata":{},"execution_count":27}],"source":["next(enumerate(loader))[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RU51H5qOumnp"},"outputs":[],"source":["# Inizialize optimizer\n","optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DGO8eAEUumnp"},"outputs":[],"source":["def train(epoch, log_steps=500, eval_steps=1000):\n","    model.train()\n","\n","    total_loss = 0\n","    for i, (pos_rw, neg_rw) in enumerate(loader):\n","        optimizer.zero_grad()\n","        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n","        loss.backward()\n","        optimizer.step()\n","\n","#         total_loss += loss.item()\n","#         if (i + 1) % log_steps == 0:\n","#             print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n","#                    f'Loss: {total_loss / log_steps:.4f}'))\n","#             total_loss = 0\n","\n","#         if (i + 1) % eval_steps == 0:\n","#             acc, f1 = test()\n","#             print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n","#                    f'Acc: {acc:.4f}, F1 score: {f1:.3f}'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iHbt8z2fumnq"},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegressionCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n","from sklearn.preprocessing import StandardScaler\n","import numpy as np\n","\n","# 1. link embeddings\n","def link_examples_to_features(link_examples, transform_node, binary_operator):\n","    return [\n","        binary_operator(transform_node[src], transform_node[dst])\n","        for src, dst in link_examples\n","    ]\n","\n","def link_prediction_classifier(max_iter = 2000):\n","    lr_clf = LogisticRegressionCV(Cs=10, cv=10, scoring=\"roc_auc\", max_iter=max_iter, \n","                                  solver=\"lbfgs\")\n","    \n","    return Pipeline(steps=[(\"sc\", StandardScaler()), (\"clf\", lr_clf)])\n","\n","# 2. training classifier\n","def train_link_prediction_model(link_examples, link_labels, get_embedding, binary_operator):\n","    clf = link_prediction_classifier()\n","    link_features = link_examples_to_features(\n","        link_examples, get_embedding, binary_operator\n","    )\n","    clf.fit(link_features, link_labels)\n","    return clf\n","\n","# 3. and 4. evaluate classifier\n","def evaluate_link_prediction_model(\n","    clf, link_examples_test, link_labels_test, get_embedding, binary_operator\n","):\n","    link_features_test = link_examples_to_features(\n","        link_examples_test, get_embedding, binary_operator)\n","    score = evaluate_scores(clf, link_features_test, link_labels_test)\n","    return score\n","\n","def evaluate_scores(clf, link_features, link_labels):\n","    y_pred = clf.predict(link_features)\n","\n","    return {\n","        \"accuracy\": accuracy_score(link_labels, y_pred),\n","        \"f1_score\": f1_score(link_labels, y_pred),\n","        \"precision\": precision_score(link_labels, y_pred),\n","        \"recall\": recall_score(link_labels, y_pred)\n","    }\n","\n","def evaluate_roc_auc(clf, link_features, link_labels):\n","    predicted = clf.predict_proba(link_features)\n","\n","    # check which class corresponds to positive links\n","    positive_column = list(clf.classes_).index(1)\n","    return roc_auc_score(link_labels, predicted[:, positive_column])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SV_m6SPDumnq"},"outputs":[],"source":["def operator_l1(u, v):\n","    return np.abs(u - v)\n","\n","def operator_l2(u, v):\n","    return (u - v) ** 2\n","\n","def run_link_prediction(binary_operator, examples, labels, embedding, examples_test, labels_test):\n","    clf = train_link_prediction_model(\n","        examples, labels, embedding, binary_operator\n","    )\n","    score = evaluate_link_prediction_model(\n","        clf,\n","        examples_test,\n","        labels_test,\n","        embedding,\n","        binary_operator,\n","    )\n","\n","    return {\n","        \"classifier\": clf,\n","        \"binary_operator\": binary_operator,\n","        \"score\": score,\n","    }\n","\n","\n","binary_operators = [operator_l1, operator_l2]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hK0DfrK4umnr"},"outputs":[],"source":["@torch.no_grad()\n","def test(train_ratio=0.1):\n","    model.eval()\n","\n","    z_customer = model('customer', batch=dataset.node_index_dict['customer'].to(device)).detach()\n","    z_product = model('product', batch=dataset.node_index_dict['product'].to(device)).detach()\n","    \n","    examples = dataset.edge_index_dict[\"customer\", \"purchases\", \"product\"].T\n","    labels = dataset.edge_label_dict[\"customer\", \"purchases\", \"product\"]\n","    \n","    examples_test = dataset.edge_index_dict[\"customer\", \"purchases_test\", \"product\"].T\n","    labels_test = dataset.edge_label_dict[\"customer\", \"purchases_test\", \"product\"]\n","    \n","    emb_128 = np.concatenate((z_customer.cpu().numpy(), z_product.cpu().numpy()), axis=0)\n","\n","    scores = run_link_prediction(operator_l1, examples.cpu(), labels.cpu(), emb_128, \n","                                 examples_test.cpu(), labels_test.cpu())[\"score\"]\n","\n","    return scores[\"accuracy\"], scores[\"f1_score\"], scores[\"precision\"], scores[\"recall\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"Tlul3Draumnr","outputId":"739c9205-f458-41ee-f610-33e09c41c8ad","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658325827050,"user_tz":-60,"elapsed":1728697,"user":{"displayName":"Group Three","userId":"07771823321101088643"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, acc: 57.30%, F1 score: 0.729, Precision: 0.573, Recall: 1.000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, acc: 57.30%, F1 score: 0.729, Precision: 0.573, Recall: 1.000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, acc: 57.30%, F1 score: 0.729, Precision: 0.573, Recall: 1.000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, acc: 57.30%, F1 score: 0.729, Precision: 0.573, Recall: 1.000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, acc: 57.30%, F1 score: 0.729, Precision: 0.573, Recall: 1.000\n","Epoch: 6, acc: 57.30%, F1 score: 0.729, Precision: 0.573, Recall: 1.000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, acc: 57.30%, F1 score: 0.729, Precision: 0.573, Recall: 1.000\n","Epoch: 8, acc: 57.30%, F1 score: 0.729, Precision: 0.573, Recall: 1.000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, acc: 57.30%, F1 score: 0.729, Precision: 0.573, Recall: 1.000\n","Epoch: 10, acc: 57.30%, F1 score: 0.729, Precision: 0.573, Recall: 1.000\n"]}],"source":["num_epoch = 10\n","for epoch in range(1, num_epoch+1):\n","    train(epoch)\n","    acc, f1, precision, recall = test()\n","    print(f'Epoch: {epoch}, acc: {100*acc:.2f}%, F1 score: {f1:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-LTlsi6umns","colab":{"base_uri":"https://localhost:8080/","height":341},"executionInfo":{"status":"error","timestamp":1658323641109,"user_tz":-60,"elapsed":513,"user":{"displayName":"Group Three","userId":"07771823321101088643"}},"outputId":"d09b2ed4-0737-4d8b-d76f-ff568bc9428b"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-0c4234e841c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz_customer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'customer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_index_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mz_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'product'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_index_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/models/metapath2vec.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, node_type, batch)\u001b[0m\n\u001b[1;32m    126\u001b[0m         :obj:`node_type`.\"\"\"\n\u001b[1;32m    127\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0memb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)"]}],"source":["z_customer = model('customer', batch=dataset.node_index_dict['customer']).detach().numpy()\n","z_product = model('product', batch=dataset.node_index_dict['product']).detach().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"suZ-kcwpumns"},"outputs":[],"source":["import numpy as np\n","\n","emb_128 = np.concatenate((z_customer, z_product), axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Svfw_yE2umnt"},"outputs":[],"source":["examples = dataset.edge_index_dict[\"customer\", \"purchases\", \"product\"].T\n","labels = dataset.edge_label_dict[\"customer\", \"purchases\", \"product\"]\n","\n","edge_embeddings = link_examples_to_features(examples, emb_128, operator_l2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uqR5aRFbumnt"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","\n","# fit and transform using PCA\n","pca = PCA(n_components=2)\n","emb2d = pca.fit_transform(emb_128)\n","\n","fig = plt.figure(figsize=(10,8))\n","ax = fig.gca()\n","ax.scatter(emb2d[50000:,0],emb2d[50000:,1], marker=\"o\", alpha=0.2, color=\"r\", label=\"Product Nodes\")\n","ax.scatter(emb2d[:50000,0],emb2d[:50000,1], marker=\"o\", alpha=0.2, color=\"g\", label=\"Customer Nodes\")\n","ax.set_title(\"PCA Analysis of Node Embeddings\")\n","ax.legend(fontsize=12, frameon=False)\n","ax.set_xlabel(\"Component A\")\n","ax.set_ylabel(\"Component B\")\n","ax.grid(True, alpha=0.1)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NdghY33Cumnu"},"outputs":[],"source":["# fit and transform using PCA\n","pca = PCA(n_components=2)\n","emb2d = pca.fit_transform(edge_embeddings)\n","\n","cdict = {0: \"red\", 1: \"green\"}\n","labeldict = {0: \"Not returned\", 1: \"Returned\"}\n","\n","fig = plt.figure(figsize=(10,8))\n","ax = fig.gca()\n","for i in range(0,2):\n","    ix = np.where(labels == i)\n","    ax.scatter(emb2d[ix,0],emb2d[ix,1], marker=\"o\", alpha=0.2, color=cdict[i], label=labeldict[i])\n","ax.set_title(\"PCA Analysis of Edge Embeddings\")\n","ax.legend(fontsize=12, frameon=False)\n","ax.set_xlabel(\"Component A\")\n","ax.set_ylabel(\"Component B\")\n","ax.grid(True, alpha=0.1)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JJRBH7Qpumnu"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xtungzIgumnu"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLp__rrWumnv"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6ucuChRumnv"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KVLv9r5sumnv","outputId":"bb180944-4e6c-4c17-85b0-086047a4f68c"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'umap'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-0fcc61e7d1bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mz_customer_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUMAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_customer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mz_product_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUMAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_product\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'umap'"]}],"source":["import umap\n","import matplotlib.pyplot as plt\n","\n","z_customer_2d = umap.UMAP().fit_transform(z_customer)\n","z_product_2d = umap.UMAP().fit_transform(z_product)\n","\n","plt.figure(figsize=(6,6))\n","plt.scatter(z_customer_2d[:,0],z_customer_2d[:,1],color=\"red\",alpha=0.5,label=\"Customer Nodes\")\n","plt.scatter(z_product_2d[:,0],z_product_2d[:,1],color=\"blue\",alpha=0.5,label=\"Product Nodes\")\n","plt.legend()\n","plt.title(\"2D embedding\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DYoRNcG3umnw"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Node2vec_pyg.ipynb","provenance":[],"machine_shape":"hm","collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}